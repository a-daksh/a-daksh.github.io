{"data":{"projects":{"edges":[{"node":{"frontmatter":{"title":"Directional Tactile device for hearing impaired","cover":{"publicURL":"/static/1072bb14653b11e2c708378659dfc4a4/image.gif","extension":"gif","childImageSharp":null},"tech":["TDoA","RaspberryPi","Python"],"github":"https://github.com/a-daksh/Directional-Assistive-device-for-deaf","external":"https://drive.google.com/file/d/1ADwG2qgMqMwadstKHuSLamN3B5sjKGv8/view"},"html":"<p>Developed a Raspberry Pi–based wearable to improve spatial hearing for individuals with hearing impairment. Designed a 4-microphone TDoA system that achieved 10° directional resolution, and integrated haptic motors to provide tactile feedback of sound direction. This reduced user response time by 30%, enabling faster localization of alarming sounds.</p>"}},{"node":{"frontmatter":{"title":"YUVAAN: Mars Rover","cover":{"publicURL":"/static/cee3b8f5f4238716626522a06744124b/image.jpg","extension":"jpg","childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#684838","images":{"fallback":{"src":"/static/cee3b8f5f4238716626522a06744124b/61c72/image.jpg","srcSet":"/static/cee3b8f5f4238716626522a06744124b/37bba/image.jpg 750w,\n/static/cee3b8f5f4238716626522a06744124b/61c72/image.jpg 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/cee3b8f5f4238716626522a06744124b/a66aa/image.webp 750w,\n/static/cee3b8f5f4238716626522a06744124b/65dd5/image.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5629629629629629}}},"tech":["CAD","ANSYS"],"github":"https://github.com/a-daksh/YUVAAN-IITG","external":"https://www.instagram.com/yuvaan_iitg/"},"html":"<p>Manufactured a  Mars Rover capable of navigating and housing soil samples. Employed ANSYS structural analysis to evaluate multiple chassis geometries and materials, optimizing for strength and weight. Designed for the IRC 2021–22 space robotics engineering challenge, organized by Mars Society South Asia.</p>"}},{"node":{"frontmatter":{"title":"Bio-Inspired Robotic Fish","cover":{"publicURL":"/static/527d3478e16f16d1ee21fbb3ec1bea69/image.png","extension":"png","childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#181818","images":{"fallback":{"src":"/static/527d3478e16f16d1ee21fbb3ec1bea69/d9927/image.jpg","srcSet":"/static/527d3478e16f16d1ee21fbb3ec1bea69/37bba/image.jpg 750w,\n/static/527d3478e16f16d1ee21fbb3ec1bea69/d9927/image.jpg 1074w","sizes":"100vw"},"sources":[{"srcSet":"/static/527d3478e16f16d1ee21fbb3ec1bea69/a66aa/image.webp 750w,\n/static/527d3478e16f16d1ee21fbb3ec1bea69/2b756/image.webp 1074w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5623836126629422}}},"tech":["RaspberryPi","Open-loop-control","SolidWorks"],"github":"https://github.com/a-daksh/Bio-Inspired-Robotic-Fish","external":null},"html":"<p>Built a biomimetic robotic fish for underwater exploration, designed to perform surveillance and mapping tasks with agile tail-driven propulsion. Developed the control system on Raspberry Pi to coordinate tail oscillation and buoyancy adjustments, enabling smooth underwater navigation and stability.</p>"}},{"node":{"frontmatter":{"title":"Pipe Traversing Robot","cover":{"publicURL":"/static/fd9435c7924e6d805f0e47592dd10cbb/image.gif","extension":"gif","childImageSharp":null},"tech":["Fusion 360","OpenCV"],"github":"https://github.com/a-daksh/Pipe-Traversing-Robot","external":null},"html":"<p>Built a 3D model for an autonomous in-pipe robot leveraging a screw-drive mechanism for smooth traversal through curved and irregular pipeline interiors. Using an onboard Raspberry Pi and camera, implemented Canny edge detection in OpenCV to identify cracks and leaks in real time.</p>"}},{"node":{"frontmatter":{"title":"Kalman Filter-Based Multi-Camera Hand Tracking","cover":{"publicURL":"/static/2c826332e44e856c1dd9f2067f97ea8a/image.png","extension":"png","childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/2c826332e44e856c1dd9f2067f97ea8a/c6607/image.png","srcSet":"/static/2c826332e44e856c1dd9f2067f97ea8a/da04c/image.png 750w,\n/static/2c826332e44e856c1dd9f2067f97ea8a/d4e32/image.png 1080w,\n/static/2c826332e44e856c1dd9f2067f97ea8a/64225/image.png 1366w,\n/static/2c826332e44e856c1dd9f2067f97ea8a/c6607/image.png 1536w","sizes":"100vw"},"sources":[{"srcSet":"/static/2c826332e44e856c1dd9f2067f97ea8a/bcdb5/image.webp 750w,\n/static/2c826332e44e856c1dd9f2067f97ea8a/0d6ef/image.webp 1080w,\n/static/2c826332e44e856c1dd9f2067f97ea8a/b3c88/image.webp 1366w,\n/static/2c826332e44e856c1dd9f2067f97ea8a/c2cdb/image.webp 1536w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4908854166666667}}},"tech":["Kalman Filter","YOLO","MediaPipe","Computer Vision"],"github":"https://github.com/a-daksh/Kalman_Filter_Based_Sensor_Fusion_for_Multi_Camera_Hand_Tracking","external":null},"html":"<p>Implemented a dual-camera sensor fusion system for hand tracking using Kalman filters, significantly improving joint angle estimation. Leveraged MediaPipe for accurate hand pose detection without camera calibration and integrated YOLO for real-time hand–object interaction tracking, evaluating performance with the Grasp Quality Index.</p>"}}]}}}